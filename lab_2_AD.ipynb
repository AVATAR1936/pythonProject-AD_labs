{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./vhi_data\\vhi_id_1_2025-03-23_01-21-53.csv successfully downloaded.\n",
      "Current working file for provinceID 1: ./vhi_data\\vhi_id_1_2025-03-23_01-21-53.csv\n",
      "File ./vhi_data\\vhi_id_2_2025-03-23_01-21-54.csv successfully downloaded.\n",
      "Current working file for provinceID 2: ./vhi_data\\vhi_id_2_2025-03-23_01-21-54.csv\n",
      "File ./vhi_data\\vhi_id_3_2025-03-23_01-21-55.csv successfully downloaded.\n",
      "Current working file for provinceID 3: ./vhi_data\\vhi_id_3_2025-03-23_01-21-55.csv\n",
      "File ./vhi_data\\vhi_id_4_2025-03-23_01-21-56.csv successfully downloaded.\n",
      "Current working file for provinceID 4: ./vhi_data\\vhi_id_4_2025-03-23_01-21-56.csv\n",
      "File ./vhi_data\\vhi_id_5_2025-03-23_01-21-57.csv successfully downloaded.\n",
      "Current working file for provinceID 5: ./vhi_data\\vhi_id_5_2025-03-23_01-21-57.csv\n",
      "File ./vhi_data\\vhi_id_6_2025-03-23_01-21-58.csv successfully downloaded.\n",
      "Current working file for provinceID 6: ./vhi_data\\vhi_id_6_2025-03-23_01-21-58.csv\n",
      "File ./vhi_data\\vhi_id_7_2025-03-23_01-21-59.csv successfully downloaded.\n",
      "Current working file for provinceID 7: ./vhi_data\\vhi_id_7_2025-03-23_01-21-59.csv\n",
      "File ./vhi_data\\vhi_id_8_2025-03-23_01-22-00.csv successfully downloaded.\n",
      "Current working file for provinceID 8: ./vhi_data\\vhi_id_8_2025-03-23_01-22-00.csv\n",
      "File ./vhi_data\\vhi_id_9_2025-03-23_01-22-00.csv successfully downloaded.\n",
      "Current working file for provinceID 9: ./vhi_data\\vhi_id_9_2025-03-23_01-22-00.csv\n",
      "File ./vhi_data\\vhi_id_10_2025-03-23_01-22-01.csv successfully downloaded.\n",
      "Current working file for provinceID 10: ./vhi_data\\vhi_id_10_2025-03-23_01-22-01.csv\n",
      "File ./vhi_data\\vhi_id_11_2025-03-23_01-22-02.csv successfully downloaded.\n",
      "Current working file for provinceID 11: ./vhi_data\\vhi_id_11_2025-03-23_01-22-02.csv\n",
      "File ./vhi_data\\vhi_id_12_2025-03-23_01-22-03.csv successfully downloaded.\n",
      "Current working file for provinceID 12: ./vhi_data\\vhi_id_12_2025-03-23_01-22-03.csv\n",
      "File ./vhi_data\\vhi_id_13_2025-03-23_01-22-04.csv successfully downloaded.\n",
      "Current working file for provinceID 13: ./vhi_data\\vhi_id_13_2025-03-23_01-22-04.csv\n",
      "File ./vhi_data\\vhi_id_14_2025-03-23_01-22-05.csv successfully downloaded.\n",
      "Current working file for provinceID 14: ./vhi_data\\vhi_id_14_2025-03-23_01-22-05.csv\n",
      "File ./vhi_data\\vhi_id_15_2025-03-23_01-22-06.csv successfully downloaded.\n",
      "Current working file for provinceID 15: ./vhi_data\\vhi_id_15_2025-03-23_01-22-06.csv\n",
      "File ./vhi_data\\vhi_id_16_2025-03-23_01-22-06.csv successfully downloaded.\n",
      "Current working file for provinceID 16: ./vhi_data\\vhi_id_16_2025-03-23_01-22-06.csv\n",
      "File ./vhi_data\\vhi_id_17_2025-03-23_01-22-07.csv successfully downloaded.\n",
      "Current working file for provinceID 17: ./vhi_data\\vhi_id_17_2025-03-23_01-22-07.csv\n",
      "File ./vhi_data\\vhi_id_18_2025-03-23_01-22-08.csv successfully downloaded.\n",
      "Current working file for provinceID 18: ./vhi_data\\vhi_id_18_2025-03-23_01-22-08.csv\n",
      "File ./vhi_data\\vhi_id_19_2025-03-23_01-22-09.csv successfully downloaded.\n",
      "Current working file for provinceID 19: ./vhi_data\\vhi_id_19_2025-03-23_01-22-09.csv\n",
      "File ./vhi_data\\vhi_id_20_2025-03-23_01-22-10.csv successfully downloaded.\n",
      "Current working file for provinceID 20: ./vhi_data\\vhi_id_20_2025-03-23_01-22-10.csv\n",
      "File ./vhi_data\\vhi_id_21_2025-03-23_01-22-11.csv successfully downloaded.\n",
      "Current working file for provinceID 21: ./vhi_data\\vhi_id_21_2025-03-23_01-22-11.csv\n",
      "File ./vhi_data\\vhi_id_22_2025-03-23_01-22-12.csv successfully downloaded.\n",
      "Current working file for provinceID 22: ./vhi_data\\vhi_id_22_2025-03-23_01-22-12.csv\n",
      "File ./vhi_data\\vhi_id_23_2025-03-23_01-22-13.csv successfully downloaded.\n",
      "Current working file for provinceID 23: ./vhi_data\\vhi_id_23_2025-03-23_01-22-13.csv\n",
      "File ./vhi_data\\vhi_id_24_2025-03-23_01-22-14.csv successfully downloaded.\n",
      "Current working file for provinceID 24: ./vhi_data\\vhi_id_24_2025-03-23_01-22-14.csv\n",
      "File ./vhi_data\\vhi_id_25_2025-03-23_01-22-15.csv successfully downloaded.\n",
      "Current working file for provinceID 25: ./vhi_data\\vhi_id_25_2025-03-23_01-22-15.csv\n",
      "File ./vhi_data\\vhi_id_26_2025-03-23_01-22-16.csv successfully downloaded.\n",
      "Current working file for provinceID 26: ./vhi_data\\vhi_id_26_2025-03-23_01-22-16.csv\n",
      "File ./vhi_data\\vhi_id_27_2025-03-23_01-22-17.csv successfully downloaded.\n",
      "Current working file for provinceID 27: ./vhi_data\\vhi_id_27_2025-03-23_01-22-17.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "def clean_line(text):\n",
    "    text = re.sub(r'<.*?>', '', text.decode('utf-8') if isinstance(text, bytes) else text).strip()\n",
    "    text = re.sub(r'\\s*,\\s*', ',', text)\n",
    "    return text\n",
    "\n",
    "data_dir = \"./vhi_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "base_url = \"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={}&year1=1981&year2=2024&type=Mean\"\n",
    "\n",
    "for province_id in range(1, 28):\n",
    "    pattern = os.path.join(data_dir, f\"vhi_id_{province_id}_*.csv\")\n",
    "    existing_files = glob.glob(pattern)\n",
    "    latest_file = max(existing_files, key=os.path.getmtime) if existing_files else None\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    new_filename = os.path.join(data_dir, f\"vhi_id_{province_id}_{timestamp}.csv\")\n",
    "\n",
    "    current_file = latest_file if latest_file else new_filename\n",
    "    url = base_url.format(province_id)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)\n",
    "        raw_new_data = response.read().splitlines()\n",
    "        \n",
    "        clean_new_data = [clean_line(line) for line in raw_new_data if clean_line(line)]\n",
    "        \n",
    "        if latest_file:\n",
    "            with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "                raw_old_data = f.readlines()\n",
    "\n",
    "            clean_old_data = [clean_line(line) for line in raw_old_data if clean_line(line)]\n",
    "            \n",
    "            if len(clean_new_data) > 1 and len(clean_old_data) > 1:\n",
    "                if sorted(set(clean_new_data[1:])) == sorted(set(clean_old_data[1:])):\n",
    "                    print(f\"No new data for provinceID {province_id}. File not updated.\")\n",
    "                else:\n",
    "                    with open(new_filename, 'w', encoding='utf-8') as f:\n",
    "                        f.writelines(\"\\n\".join(clean_new_data))\n",
    "                    print(f\"Updated data found for provinceID {province_id}. New file saved as {new_filename}.\")\n",
    "                    \n",
    "                    os.remove(latest_file)\n",
    "                    print(f\"Old file {latest_file} deleted.\")\n",
    "                    \n",
    "                    current_file = new_filename\n",
    "            else:\n",
    "                print(f\"Error: Not enough data to compare for provinceID {province_id}.\")\n",
    "        else:\n",
    "            with open(new_filename, 'w', encoding='utf-8') as f:\n",
    "                f.writelines(\"\\n\".join(clean_new_data))\n",
    "            print(f\"File {new_filename} successfully downloaded.\")\n",
    "            \n",
    "            current_file = new_filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading provinceID {province_id}: {e}\")\n",
    "\n",
    "    print(f\"Current working file for provinceID {province_id}: {current_file}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:17.964990Z",
     "start_time": "2025-03-22T23:21:53.680056800Z"
    }
   },
   "id": "6b12cd125ef7943e"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Province in: vhi_id_10_2025-03-23_01-22-01.csv\n",
      "Updated Province in: vhi_id_11_2025-03-23_01-22-02.csv\n",
      "Updated Province in: vhi_id_12_2025-03-23_01-22-03.csv\n",
      "Updated Province in: vhi_id_13_2025-03-23_01-22-04.csv\n",
      "Updated Province in: vhi_id_14_2025-03-23_01-22-05.csv\n",
      "Updated Province in: vhi_id_15_2025-03-23_01-22-06.csv\n",
      "Updated Province in: vhi_id_16_2025-03-23_01-22-06.csv\n",
      "Updated Province in: vhi_id_17_2025-03-23_01-22-07.csv\n",
      "Updated Province in: vhi_id_18_2025-03-23_01-22-08.csv\n",
      "Updated Province in: vhi_id_19_2025-03-23_01-22-09.csv\n",
      "Updated Province in: vhi_id_1_2025-03-23_01-21-53.csv\n",
      "Updated Province in: vhi_id_20_2025-03-23_01-22-10.csv\n",
      "Updated Province in: vhi_id_21_2025-03-23_01-22-11.csv\n",
      "Updated Province in: vhi_id_22_2025-03-23_01-22-12.csv\n",
      "Updated Province in: vhi_id_23_2025-03-23_01-22-13.csv\n",
      "Updated Province in: vhi_id_24_2025-03-23_01-22-14.csv\n",
      "Updated Province in: vhi_id_25_2025-03-23_01-22-15.csv\n",
      "Updated Province in: vhi_id_26_2025-03-23_01-22-16.csv\n",
      "Updated Province in: vhi_id_27_2025-03-23_01-22-17.csv\n",
      "Updated Province in: vhi_id_2_2025-03-23_01-21-54.csv\n",
      "Updated Province in: vhi_id_3_2025-03-23_01-21-55.csv\n",
      "Updated Province in: vhi_id_4_2025-03-23_01-21-56.csv\n",
      "Updated Province in: vhi_id_5_2025-03-23_01-21-57.csv\n",
      "Updated Province in: vhi_id_6_2025-03-23_01-21-58.csv\n",
      "Updated Province in: vhi_id_7_2025-03-23_01-21-59.csv\n",
      "Updated Province in: vhi_id_8_2025-03-23_01-22-00.csv\n",
      "Updated Province in: vhi_id_9_2025-03-23_01-22-00.csv\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    1: 25, 2: 27, 3: 26, 4: 18, 5: 3, 6: 4, 7: 8, 8: 22, 9: 23, 10: 24,\n",
    "    11: 10, 12: 9, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16, 19: 17,\n",
    "    20: 19, 21: 20, 22: 21, 23: 6, 24: 1, 25: 2, 26: 7, 27: 5\n",
    "}\n",
    "\n",
    "def process_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            header = lines[0]\n",
    "            match = re.search(r\"Province=\\s*(\\d+)\", header)\n",
    "            if match:\n",
    "                province_id = int(match.group(1))\n",
    "                new_id = id_mapping.get(province_id, province_id)\n",
    "                header = re.sub(r\"Province=\\s*\\d+\", f\"Province= {new_id}\", header)\n",
    "                lines[0] = header\n",
    "\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.writelines(lines)\n",
    "            \n",
    "            print(f\"Updated Province in: {filename}\")\n",
    "\n",
    "process_files(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:18.257986200Z",
     "start_time": "2025-03-22T23:22:17.969675800Z"
    }
   },
   "id": "82104defe26623e"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./vhi_data\\vhi_id_10_2025-03-23_01-22-01.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_11_2025-03-23_01-22-02.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_12_2025-03-23_01-22-03.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_13_2025-03-23_01-22-04.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_14_2025-03-23_01-22-05.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_15_2025-03-23_01-22-06.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_16_2025-03-23_01-22-06.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_17_2025-03-23_01-22-07.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_18_2025-03-23_01-22-08.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_19_2025-03-23_01-22-09.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_1_2025-03-23_01-21-53.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_20_2025-03-23_01-22-10.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_21_2025-03-23_01-22-11.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_22_2025-03-23_01-22-12.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_23_2025-03-23_01-22-13.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_24_2025-03-23_01-22-14.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_25_2025-03-23_01-22-15.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_26_2025-03-23_01-22-16.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_27_2025-03-23_01-22-17.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_2_2025-03-23_01-21-54.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_3_2025-03-23_01-21-55.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_4_2025-03-23_01-21-56.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_5_2025-03-23_01-21-57.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_6_2025-03-23_01-21-58.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_7_2025-03-23_01-21-59.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_8_2025-03-23_01-22-00.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_9_2025-03-23_01-22-00.csv processed successfully.\n",
      "File 'vhi_final.csv' saved successfully!\n",
      "             SMN     SMT    VCI    TCI    VHI  id\n",
      "Year Week                                        \n",
      "1982 1     0.068  263.59  63.47  28.34  45.90   1\n",
      "     2     0.074  265.78  67.62  23.05  45.34   1\n",
      "     3     0.076  267.19  69.37  20.40  44.88   1\n",
      "     4     0.075  268.57  65.26  17.93  41.60   1\n",
      "     5     0.072  269.24  58.58  20.00  39.29   1\n"
     ]
    }
   ],
   "source": [
    "headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'empty']\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                first_line = f.readline()\n",
    "                match = re.search(r'Province=\\s*(\\d+)', first_line)\n",
    "                if not match:\n",
    "                    print(f\"Province ID not found in file {file}, skipping...\")\n",
    "                    continue\n",
    "                province_id = int(match.group(1))\n",
    "            \n",
    "            # Load data\n",
    "            df = pd.read_csv(file_path, header=1, names=headers)\n",
    "            df = df.drop(columns=[\"empty\"], errors=\"ignore\")\n",
    "            df = df.set_index([\"Year\", \"Week\"])\n",
    "            \n",
    "            df[\"id\"] = province_id\n",
    "            dfs.append(df)\n",
    "            print(f\"File {file_path} processed successfully.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "if dfs:\n",
    "    final_df = pd.concat(dfs)\n",
    "    final_df = final_df.sort_values(by=[\"Year\", \"id\"])\n",
    "    final_df.to_csv(\"vhi_final.csv\")\n",
    "    print(\"File 'vhi_final.csv' saved successfully!\")\n",
    "    print(final_df.head())\n",
    "else:\n",
    "    print(\"No suitable files found for merging.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:18.830794700Z",
     "start_time": "2025-03-22T23:22:18.263737400Z"
    }
   },
   "id": "644fa8536e3090c0"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year  Week\n",
      "2005  1       52.56\n",
      "      2       53.32\n",
      "      3       55.39\n",
      "      4        56.2\n",
      "      5       56.13\n",
      "      6        56.5\n",
      "      7       56.33\n",
      "      8        56.9\n",
      "      9       57.88\n",
      "      10      58.26\n",
      "      11       58.5\n",
      "      12      58.78\n",
      "      13       57.3\n",
      "      14      53.32\n",
      "      15      49.03\n",
      "      16      47.26\n",
      "      18      50.74\n",
      "      19      52.84\n",
      "      20      46.99\n",
      "      21      54.93\n",
      "      22      55.82\n",
      "      23      57.42\n",
      "      24       56.3\n",
      "      25      55.71\n",
      "      26      56.47\n",
      "      27       56.3\n",
      "      28      56.74\n",
      "      29      61.33\n",
      "      30      58.39\n",
      "      31      60.51\n",
      "      32      62.05\n",
      "      33       61.9\n",
      "      34      62.77\n",
      "      35      61.78\n",
      "      36      58.61\n",
      "      37      55.98\n",
      "      38      54.65\n",
      "      39      53.14\n",
      "      40      52.01\n",
      "      41      51.73\n",
      "      42      51.16\n",
      "      43      50.91\n",
      "      44      52.32\n",
      "      45      54.23\n",
      "      46      53.13\n",
      "      47      49.57\n",
      "      48      49.13\n",
      "      49      48.69\n",
      "      50      47.39\n",
      "      51       47.0\n",
      "      52      46.53\n",
      "Name: VHI, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path, index_col=[\"Year\", \"Week\"]).replace(-1, pd.NA).dropna()\n",
    "\n",
    "def get_vhi_series(df, region_id, year):\n",
    "    return df.query(\"id == @region_id and Year == @year\")[\"VHI\"]\n",
    "\n",
    "final_df = load_data(\"vhi_final.csv\")\n",
    "print(get_vhi_series(final_df, 8, 2005))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:18.905646500Z",
     "start_time": "2025-03-22T23:22:18.832368200Z"
    }
   },
   "id": "a40ccab338ec8d9"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 21.56, 'max': 62.36, 'mean': 44.679423076923094, 'median': 45.269999999999996}\n"
     ]
    }
   ],
   "source": [
    "def get_extremes(df, region_ids, years):\n",
    "    selected_data = df.loc[df.index.get_level_values(\"Year\").isin(years) & df[\"id\"].isin(region_ids), \"VHI\"]\n",
    "    selected_data = selected_data.dropna()\n",
    "    return {\n",
    "        \"min\": float(selected_data.min()),\n",
    "        \"max\": float(selected_data.max()),\n",
    "        \"mean\": float(selected_data.mean()),\n",
    "        \"median\": float(selected_data.median())\n",
    "    }\n",
    "\n",
    "print(get_extremes(final_df, [1, 4], range(1999, 2000)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:18.950322600Z",
     "start_time": "2025-03-22T23:22:18.907161600Z"
    }
   },
   "id": "961ff27ca1be14de"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             3      5\n",
      "Year Week              \n",
      "1995 4     57.56  49.83\n",
      "     5     51.35  47.92\n",
      "     6     42.64  45.16\n",
      "     7     34.23  41.58\n",
      "     8     29.13  39.64\n",
      "     9     26.64  38.95\n",
      "     10    25.49  38.95\n",
      "     11    25.71   37.8\n",
      "     12    26.72  41.42\n",
      "     13    28.79  43.85\n",
      "     14    29.97   45.1\n",
      "     15    31.51  46.07\n",
      "     16    33.09   46.2\n",
      "     17    38.15  49.62\n",
      "     18    43.17  50.76\n",
      "     19    46.68  51.57\n",
      "     20    49.03  53.89\n",
      "     21    50.29  52.93\n",
      "     22    49.21  50.15\n",
      "     23    47.87  49.23\n",
      "     24    49.91  49.43\n",
      "     25    56.72  50.25\n",
      "     26    61.35  49.28\n",
      "     27    62.43  45.55\n",
      "     28    62.02  44.65\n",
      "     29    62.29  44.75\n",
      "     30    62.96  45.42\n",
      "     31    63.84  46.52\n",
      "     32    64.83  47.43\n",
      "     33    65.45  46.96\n",
      "     34    65.59  44.99\n",
      "     35    65.31  43.55\n",
      "     36    63.61  46.98\n",
      "     37    60.76  49.12\n",
      "     38    60.09  51.85\n",
      "     39     58.9  50.01\n",
      "     40    57.49  47.33\n",
      "     41    55.01  46.54\n",
      "     42    52.34   48.3\n",
      "     43    50.63  52.19\n",
      "     44    46.97  50.34\n",
      "     45    44.04  49.27\n",
      "     46    40.58  48.74\n",
      "     47    36.14  49.47\n",
      "     48    32.87  47.84\n",
      "     49    31.97  44.94\n",
      "     50    27.78  40.05\n",
      "     51    26.11  35.98\n",
      "     52    28.88  34.94\n",
      "1996 1     34.44  37.95\n",
      "     2     38.04  39.55\n",
      "     3      37.4  39.41\n",
      "     4      37.7  41.17\n",
      "     5      39.8  42.36\n",
      "     6     42.01  43.64\n",
      "     7     42.43   44.6\n",
      "     8     42.13  44.65\n",
      "     9      42.4  43.43\n",
      "     10     42.4  41.89\n",
      "     11    42.21   40.6\n",
      "     12    41.55  40.94\n",
      "     13    42.32  42.15\n",
      "     14    43.15  45.79\n",
      "     15     43.9  46.49\n",
      "     16     44.1  44.74\n",
      "     17    47.39  44.28\n",
      "     18    50.74  42.17\n",
      "     19    53.13  43.23\n",
      "     20    54.72  43.19\n",
      "     21    58.03  41.86\n",
      "     22    57.22  40.16\n",
      "     23    52.99  38.54\n",
      "     24    47.59  35.32\n",
      "     25    41.76  34.45\n",
      "     26    36.71  35.23\n",
      "     27    32.81  37.73\n",
      "     28    29.41  43.22\n",
      "     29    27.68   48.3\n",
      "     30    29.05   53.1\n",
      "     31    33.47  55.74\n",
      "     32    39.27  56.97\n",
      "     33    46.61   58.5\n",
      "     34    54.22  59.78\n",
      "     35    62.22  61.97\n",
      "     36    69.46  66.69\n",
      "     37     74.1  69.73\n",
      "     38    75.05  69.17\n",
      "     39    72.96  65.33\n",
      "     40    68.84  57.57\n",
      "     41    62.16  52.08\n",
      "     42    55.88  47.19\n",
      "     43    50.39  44.72\n",
      "     44    42.91   42.6\n",
      "     45    40.06   39.6\n",
      "     46    39.34  38.31\n",
      "     47    39.13  39.33\n",
      "     48    40.03  41.66\n",
      "     49    39.62  40.23\n",
      "     50    38.98  38.71\n",
      "     51     40.2   37.9\n",
      "     52    38.97  38.44\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_for_range(df, region_ids, start_year, end_year):\n",
    "    return df.loc[\n",
    "        (df.index.get_level_values(\"Year\") >= start_year) &\n",
    "        (df.index.get_level_values(\"Year\") <= end_year) &\n",
    "        df[\"id\"].isin(region_ids),\n",
    "        [\"id\", \"VHI\"]\n",
    "    ].set_index(\"id\", append=True)[\"VHI\"].unstack()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(get_vhi_for_range(final_df, [3, 5], 1995, 1996))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:18.959112500Z",
     "start_time": "2025-03-22T23:22:18.922394300Z"
    }
   },
   "id": "8dad9b232bc1bb2a"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Week  id           Region    VHI\n",
      "25316  2000    45   1        Вінницька  12.26\n",
      "25317  2000    46   1        Вінницька  11.28\n",
      "25318  2000    47   1        Вінницька  11.25\n",
      "25319  2000    48   1        Вінницька  11.38\n",
      "25320  2000    49   1        Вінницька  12.91\n",
      "25321  2000    50   1        Вінницька  14.20\n",
      "25729  2000    42   9             Київ  14.89\n",
      "25730  2000    43   9             Київ  12.76\n",
      "25731  2000    44   9             Київ   7.81\n",
      "25732  2000    45   9             Київ   6.49\n",
      "25733  2000    46   9             Київ   6.58\n",
      "25734  2000    47   9             Київ   6.71\n",
      "25735  2000    48   9             Київ   7.56\n",
      "25736  2000    49   9             Київ   9.25\n",
      "25737  2000    50   9             Київ  10.94\n",
      "25738  2000    51   9             Київ  12.28\n",
      "25783  2000    44  10         Київська  12.51\n",
      "25784  2000    45  10         Київська  10.60\n",
      "25785  2000    46  10         Київська  11.20\n",
      "25786  2000    47  10         Київська  12.32\n",
      "25787  2000    48  10         Київська  14.65\n",
      "26252  2000    45  19      Севастополь  13.14\n",
      "26253  2000    46  19      Севастополь   9.50\n",
      "26254  2000    47  19      Севастополь   8.14\n",
      "26255  2000    48  19      Севастополь   9.69\n",
      "26256  2000    49  19      Севастополь  11.20\n",
      "26257  2000    50  19      Севастополь  11.36\n",
      "26258  2000    51  19      Севастополь  12.77\n",
      "26409  2000    46  22       Харківська  14.61\n",
      "26410  2000    47  22       Харківська  11.33\n",
      "26411  2000    48  22       Харківська   9.36\n",
      "26412  2000    49  22       Харківська   9.45\n",
      "26413  2000    50  22       Харківська   9.73\n",
      "26414  2000    51  22       Харківська  11.45\n",
      "26415  2000    52  22       Харківська  14.29\n",
      "26563  2000    44  25        Черкаська  14.64\n",
      "26564  2000    45  25        Черкаська  11.82\n",
      "26565  2000    46  25        Черкаська  10.81\n",
      "26566  2000    47  25        Черкаська  10.68\n",
      "26567  2000    48  25        Черкаська  12.30\n",
      "26568  2000    49  25        Черкаська  14.24\n",
      "35438  2007    27   7       Запорізька  14.26\n",
      "35439  2007    28   7       Запорізька  13.39\n",
      "35440  2007    29   7       Запорізька  13.33\n",
      "35441  2007    30   7       Запорізька  13.06\n",
      "35442  2007    31   7       Запорізька  13.13\n",
      "35443  2007    32   7       Запорізька  12.51\n",
      "35444  2007    33   7       Запорізька  11.55\n",
      "35445  2007    34   7       Запорізька  10.88\n",
      "35446  2007    35   7       Запорізька  11.06\n",
      "35447  2007    36   7       Запорізька  12.05\n",
      "35448  2007    37   7       Запорізька  13.84\n",
      "35797  2007    22  14     Миколаївська  11.44\n",
      "35798  2007    23  14     Миколаївська   7.78\n",
      "35799  2007    24  14     Миколаївська   6.44\n",
      "35800  2007    25  14     Миколаївська   6.12\n",
      "35801  2007    26  14     Миколаївська   6.11\n",
      "35802  2007    27  14     Миколаївська   5.94\n",
      "35803  2007    28  14     Миколаївська   6.36\n",
      "35804  2007    29  14     Миколаївська   7.61\n",
      "35805  2007    30  14     Миколаївська   9.45\n",
      "35806  2007    31  14     Миколаївська  11.70\n",
      "35852  2007    25  15          Одеська  11.88\n",
      "35853  2007    26  15          Одеська   9.21\n",
      "35854  2007    27  15          Одеська   7.08\n",
      "35855  2007    28  15          Одеська   5.90\n",
      "35856  2007    29  15          Одеська   5.52\n",
      "35857  2007    30  15          Одеська   5.85\n",
      "35858  2007    31  15          Одеська   6.82\n",
      "35859  2007    32  15          Одеська   8.86\n",
      "35860  2007    33  15          Одеська  11.91\n",
      "36013  2007    30  18  Республіка Крим  14.98\n",
      "36014  2007    31  18  Республіка Крим  14.23\n",
      "36015  2007    32  18  Республіка Крим  13.79\n",
      "36016  2007    33  18  Республіка Крим  13.41\n",
      "36017  2007    34  18  Республіка Крим  13.28\n",
      "36018  2007    35  18  Республіка Крим  14.36\n",
      "36266  2007    23  23       Херсонська  12.41\n",
      "36267  2007    24  23       Херсонська  12.23\n",
      "36268  2007    25  23       Херсонська  12.99\n",
      "36269  2007    26  23       Херсонська  13.33\n",
      "36270  2007    27  23       Херсонська  12.88\n",
      "36271  2007    28  23       Херсонська  12.63\n",
      "36272  2007    29  23       Херсонська  12.96\n",
      "36273  2007    30  23       Херсонська  13.48\n",
      "36274  2007    31  23       Херсонська  14.05\n",
      "36275  2007    32  23       Херсонська  14.41\n",
      "36276  2007    33  23       Херсонська  14.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_drought_years(df, threshold=20):\n",
    "    df = df.reset_index()\n",
    "    df = df[df[\"VHI\"] != -1]\n",
    "    \n",
    "    total_regions = len(df[\"id\"].unique())\n",
    "    critical_regions = int((threshold / 100) * total_regions)\n",
    "    drought_df = df[df[\"VHI\"] < 15]\n",
    "    drought_counts = drought_df.groupby(\"Year\")[\"id\"].nunique()\n",
    "    drought_years = drought_counts[drought_counts >= critical_regions].index.tolist()\n",
    "    extreme_droughts = drought_df[drought_df[\"Year\"].isin(drought_years)].copy()\n",
    "    \n",
    "    regions = {\n",
    "        1: \"Вінницька\", 2: \"Волинська\", 3: \"Дніпропетровська\", 4: \"Донецька\", 5: \"Житомирська\",\n",
    "        6: \"Закарпатська\", 7: \"Запорізька\", 8: \"Івано-Франківська\", 9: \"Київ\", 10: \"Київська\",\n",
    "        11: \"Кіровоградська\", 12: \"Луганська\", 13: \"Львівська\", 14: \"Миколаївська\", 15: \"Одеська\",\n",
    "        16: \"Полтавська\", 17: \"Рівненська\", 18: \"Республіка Крим\", 19: \"Севастополь\", 20: \"Сумська\",\n",
    "        21: \"Тернопільська\", 22: \"Харківська\", 23: \"Херсонська\", 24: \"Хмельницька\", 25: \"Черкаська\",\n",
    "        26: \"Чернівецька\", 27: \"Чернігівська\"\n",
    "    }\n",
    "    extreme_droughts[\"Region\"] = extreme_droughts[\"id\"].map(regions)\n",
    "    \n",
    "    return extreme_droughts[[\"Year\", \"Week\", \"id\", \"Region\", \"VHI\"]]\n",
    "\n",
    "df = pd.read_csv(\"vhi_final.csv\")\n",
    "\n",
    "result = detect_drought_years(df, threshold=20)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-22T23:22:19.011042400Z",
     "start_time": "2025-03-22T23:22:18.940765200Z"
    }
   },
   "id": "4c8c4c06a557618b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2fafb03050caf179"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
