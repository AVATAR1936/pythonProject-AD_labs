{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./vhi_data\\vhi_id_1_2025-03-11_14-37-10.csv successfully downloaded.\n",
      "Current working file for provinceID 1: ./vhi_data\\vhi_id_1_2025-03-11_14-37-10.csv\n",
      "File ./vhi_data\\vhi_id_2_2025-03-11_14-37-12.csv successfully downloaded.\n",
      "Current working file for provinceID 2: ./vhi_data\\vhi_id_2_2025-03-11_14-37-12.csv\n",
      "File ./vhi_data\\vhi_id_3_2025-03-11_14-37-13.csv successfully downloaded.\n",
      "Current working file for provinceID 3: ./vhi_data\\vhi_id_3_2025-03-11_14-37-13.csv\n",
      "File ./vhi_data\\vhi_id_4_2025-03-11_14-37-14.csv successfully downloaded.\n",
      "Current working file for provinceID 4: ./vhi_data\\vhi_id_4_2025-03-11_14-37-14.csv\n",
      "File ./vhi_data\\vhi_id_5_2025-03-11_14-37-15.csv successfully downloaded.\n",
      "Current working file for provinceID 5: ./vhi_data\\vhi_id_5_2025-03-11_14-37-15.csv\n",
      "File ./vhi_data\\vhi_id_6_2025-03-11_14-37-16.csv successfully downloaded.\n",
      "Current working file for provinceID 6: ./vhi_data\\vhi_id_6_2025-03-11_14-37-16.csv\n",
      "File ./vhi_data\\vhi_id_7_2025-03-11_14-37-17.csv successfully downloaded.\n",
      "Current working file for provinceID 7: ./vhi_data\\vhi_id_7_2025-03-11_14-37-17.csv\n",
      "File ./vhi_data\\vhi_id_8_2025-03-11_14-37-17.csv successfully downloaded.\n",
      "Current working file for provinceID 8: ./vhi_data\\vhi_id_8_2025-03-11_14-37-17.csv\n",
      "File ./vhi_data\\vhi_id_9_2025-03-11_14-37-18.csv successfully downloaded.\n",
      "Current working file for provinceID 9: ./vhi_data\\vhi_id_9_2025-03-11_14-37-18.csv\n",
      "File ./vhi_data\\vhi_id_10_2025-03-11_14-37-19.csv successfully downloaded.\n",
      "Current working file for provinceID 10: ./vhi_data\\vhi_id_10_2025-03-11_14-37-19.csv\n",
      "File ./vhi_data\\vhi_id_11_2025-03-11_14-37-20.csv successfully downloaded.\n",
      "Current working file for provinceID 11: ./vhi_data\\vhi_id_11_2025-03-11_14-37-20.csv\n",
      "File ./vhi_data\\vhi_id_12_2025-03-11_14-37-21.csv successfully downloaded.\n",
      "Current working file for provinceID 12: ./vhi_data\\vhi_id_12_2025-03-11_14-37-21.csv\n",
      "File ./vhi_data\\vhi_id_13_2025-03-11_14-37-22.csv successfully downloaded.\n",
      "Current working file for provinceID 13: ./vhi_data\\vhi_id_13_2025-03-11_14-37-22.csv\n",
      "File ./vhi_data\\vhi_id_14_2025-03-11_14-37-22.csv successfully downloaded.\n",
      "Current working file for provinceID 14: ./vhi_data\\vhi_id_14_2025-03-11_14-37-22.csv\n",
      "File ./vhi_data\\vhi_id_15_2025-03-11_14-37-23.csv successfully downloaded.\n",
      "Current working file for provinceID 15: ./vhi_data\\vhi_id_15_2025-03-11_14-37-23.csv\n",
      "File ./vhi_data\\vhi_id_16_2025-03-11_14-37-24.csv successfully downloaded.\n",
      "Current working file for provinceID 16: ./vhi_data\\vhi_id_16_2025-03-11_14-37-24.csv\n",
      "File ./vhi_data\\vhi_id_17_2025-03-11_14-37-25.csv successfully downloaded.\n",
      "Current working file for provinceID 17: ./vhi_data\\vhi_id_17_2025-03-11_14-37-25.csv\n",
      "File ./vhi_data\\vhi_id_18_2025-03-11_14-37-26.csv successfully downloaded.\n",
      "Current working file for provinceID 18: ./vhi_data\\vhi_id_18_2025-03-11_14-37-26.csv\n",
      "File ./vhi_data\\vhi_id_19_2025-03-11_14-37-27.csv successfully downloaded.\n",
      "Current working file for provinceID 19: ./vhi_data\\vhi_id_19_2025-03-11_14-37-27.csv\n",
      "File ./vhi_data\\vhi_id_20_2025-03-11_14-37-28.csv successfully downloaded.\n",
      "Current working file for provinceID 20: ./vhi_data\\vhi_id_20_2025-03-11_14-37-28.csv\n",
      "File ./vhi_data\\vhi_id_21_2025-03-11_14-37-29.csv successfully downloaded.\n",
      "Current working file for provinceID 21: ./vhi_data\\vhi_id_21_2025-03-11_14-37-29.csv\n",
      "File ./vhi_data\\vhi_id_22_2025-03-11_14-37-29.csv successfully downloaded.\n",
      "Current working file for provinceID 22: ./vhi_data\\vhi_id_22_2025-03-11_14-37-29.csv\n",
      "File ./vhi_data\\vhi_id_23_2025-03-11_14-37-30.csv successfully downloaded.\n",
      "Current working file for provinceID 23: ./vhi_data\\vhi_id_23_2025-03-11_14-37-30.csv\n",
      "File ./vhi_data\\vhi_id_24_2025-03-11_14-37-31.csv successfully downloaded.\n",
      "Current working file for provinceID 24: ./vhi_data\\vhi_id_24_2025-03-11_14-37-31.csv\n",
      "File ./vhi_data\\vhi_id_25_2025-03-11_14-37-32.csv successfully downloaded.\n",
      "Current working file for provinceID 25: ./vhi_data\\vhi_id_25_2025-03-11_14-37-32.csv\n",
      "File ./vhi_data\\vhi_id_26_2025-03-11_14-37-33.csv successfully downloaded.\n",
      "Current working file for provinceID 26: ./vhi_data\\vhi_id_26_2025-03-11_14-37-33.csv\n",
      "File ./vhi_data\\vhi_id_27_2025-03-11_14-37-34.csv successfully downloaded.\n",
      "Current working file for provinceID 27: ./vhi_data\\vhi_id_27_2025-03-11_14-37-34.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "def clean_line(text):\n",
    "    text = re.sub(r'<.*?>', '', text.decode('utf-8') if isinstance(text, bytes) else text).strip()\n",
    "    text = re.sub(r'\\s*,\\s*', ',', text)\n",
    "    return text\n",
    "\n",
    "data_dir = \"./vhi_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "base_url = \"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={}&year1=1981&year2=2024&type=Mean\"\n",
    "\n",
    "for province_id in range(1, 28):\n",
    "    pattern = os.path.join(data_dir, f\"vhi_id_{province_id}_*.csv\")\n",
    "    existing_files = glob.glob(pattern)\n",
    "    latest_file = max(existing_files, key=os.path.getmtime) if existing_files else None\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    new_filename = os.path.join(data_dir, f\"vhi_id_{province_id}_{timestamp}.csv\")\n",
    "\n",
    "    current_file = latest_file if latest_file else new_filename\n",
    "    url = base_url.format(province_id)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)\n",
    "        raw_new_data = response.read().splitlines()\n",
    "        \n",
    "        clean_new_data = [clean_line(line) for line in raw_new_data if clean_line(line)]\n",
    "        \n",
    "        if latest_file:\n",
    "            with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "                raw_old_data = f.readlines()\n",
    "\n",
    "            clean_old_data = [clean_line(line) for line in raw_old_data if clean_line(line)]\n",
    "            \n",
    "            if len(clean_new_data) > 1 and len(clean_old_data) > 1:\n",
    "                if sorted(set(clean_new_data[1:])) == sorted(set(clean_old_data[1:])):\n",
    "                    print(f\"No new data for provinceID {province_id}. File not updated.\")\n",
    "                else:\n",
    "                    with open(new_filename, 'w', encoding='utf-8') as f:\n",
    "                        f.writelines(\"\\n\".join(clean_new_data))\n",
    "                    print(f\"Updated data found for provinceID {province_id}. New file saved as {new_filename}.\")\n",
    "                    \n",
    "                    os.remove(latest_file)\n",
    "                    print(f\"Old file {latest_file} deleted.\")\n",
    "                    \n",
    "                    current_file = new_filename\n",
    "            else:\n",
    "                print(f\"Error: Not enough data to compare for provinceID {province_id}.\")\n",
    "        else:\n",
    "            with open(new_filename, 'w', encoding='utf-8') as f:\n",
    "                f.writelines(\"\\n\".join(clean_new_data))\n",
    "            print(f\"File {new_filename} successfully downloaded.\")\n",
    "            \n",
    "            current_file = new_filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading provinceID {province_id}: {e}\")\n",
    "\n",
    "    print(f\"Current working file for provinceID {province_id}: {current_file}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:37:35.359120700Z",
     "start_time": "2025-03-11T12:37:09.866258200Z"
    }
   },
   "id": "6b12cd125ef7943e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Province in: vhi_id_10_2025-03-11_14-37-19.csv\n",
      "Updated Province in: vhi_id_11_2025-03-11_14-37-20.csv\n",
      "Updated Province in: vhi_id_12_2025-03-11_14-37-21.csv\n",
      "Updated Province in: vhi_id_13_2025-03-11_14-37-22.csv\n",
      "Updated Province in: vhi_id_14_2025-03-11_14-37-22.csv\n",
      "Updated Province in: vhi_id_15_2025-03-11_14-37-23.csv\n",
      "Updated Province in: vhi_id_16_2025-03-11_14-37-24.csv\n",
      "Updated Province in: vhi_id_17_2025-03-11_14-37-25.csv\n",
      "Updated Province in: vhi_id_18_2025-03-11_14-37-26.csv\n",
      "Updated Province in: vhi_id_19_2025-03-11_14-37-27.csv\n",
      "Updated Province in: vhi_id_1_2025-03-11_14-37-10.csv\n",
      "Updated Province in: vhi_id_20_2025-03-11_14-37-28.csv\n",
      "Updated Province in: vhi_id_21_2025-03-11_14-37-29.csv\n",
      "Updated Province in: vhi_id_22_2025-03-11_14-37-29.csv\n",
      "Updated Province in: vhi_id_23_2025-03-11_14-37-30.csv\n",
      "Updated Province in: vhi_id_24_2025-03-11_14-37-31.csv\n",
      "Updated Province in: vhi_id_25_2025-03-11_14-37-32.csv\n",
      "Updated Province in: vhi_id_26_2025-03-11_14-37-33.csv\n",
      "Updated Province in: vhi_id_27_2025-03-11_14-37-34.csv\n",
      "Updated Province in: vhi_id_2_2025-03-11_14-37-12.csv\n",
      "Updated Province in: vhi_id_3_2025-03-11_14-37-13.csv\n",
      "Updated Province in: vhi_id_4_2025-03-11_14-37-14.csv\n",
      "Updated Province in: vhi_id_5_2025-03-11_14-37-15.csv\n",
      "Updated Province in: vhi_id_6_2025-03-11_14-37-16.csv\n",
      "Updated Province in: vhi_id_7_2025-03-11_14-37-17.csv\n",
      "Updated Province in: vhi_id_8_2025-03-11_14-37-17.csv\n",
      "Updated Province in: vhi_id_9_2025-03-11_14-37-18.csv\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    1: 25, 2: 27, 3: 26, 4: 1, 5: 4, 6: 5, 7: 9, 8: 22, 9: 23, 10: 24,\n",
    "    11: 12, 12: 10, 13: 11, 14: 13, 15: 14, 16: 15, 17: 17, 18: 18, 19: 19,\n",
    "    20: 16, 21: 20, 22: 21, 23: 2, 24: 3, 25: 7, 26: 8, 27: 6\n",
    "}\n",
    "\n",
    "def process_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            header = lines[0]\n",
    "            match = re.search(r\"Province=\\s*(\\d+)\", header)\n",
    "            if match:\n",
    "                province_id = int(match.group(1))\n",
    "                new_id = id_mapping.get(province_id, province_id)\n",
    "                header = re.sub(r\"Province=\\s*\\d+\", f\"Province= {new_id}\", header)\n",
    "                lines[0] = header\n",
    "\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.writelines(lines)\n",
    "            \n",
    "            print(f\"Updated Province in: {filename}\")\n",
    "\n",
    "process_files(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:38:23.262033800Z",
     "start_time": "2025-03-11T12:38:23.175245400Z"
    }
   },
   "id": "82104defe26623e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./vhi_data\\vhi_id_1_2025-03-11_14-37-10.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_2_2025-03-11_14-37-12.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_3_2025-03-11_14-37-13.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_4_2025-03-11_14-37-14.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_5_2025-03-11_14-37-15.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_6_2025-03-11_14-37-16.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_7_2025-03-11_14-37-17.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_8_2025-03-11_14-37-17.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_9_2025-03-11_14-37-18.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_10_2025-03-11_14-37-19.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_11_2025-03-11_14-37-20.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_12_2025-03-11_14-37-21.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_13_2025-03-11_14-37-22.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_14_2025-03-11_14-37-22.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_15_2025-03-11_14-37-23.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_16_2025-03-11_14-37-24.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_17_2025-03-11_14-37-25.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_18_2025-03-11_14-37-26.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_19_2025-03-11_14-37-27.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_20_2025-03-11_14-37-28.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_21_2025-03-11_14-37-29.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_22_2025-03-11_14-37-29.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_23_2025-03-11_14-37-30.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_24_2025-03-11_14-37-31.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_25_2025-03-11_14-37-32.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_26_2025-03-11_14-37-33.csv processed successfully.\n",
      "File ./vhi_data\\vhi_id_27_2025-03-11_14-37-34.csv processed successfully.\n",
      "File 'vhi_final.csv' saved successfully!\n",
      "               1                                   2                        \\\n",
      "             SMN     SMT    VCI    TCI    VHI    SMN     SMT    VCI    TCI   \n",
      "Year Week                                                                    \n",
      "1982 1     0.053  260.31  45.01  39.46  42.23  0.060  258.80  38.36  47.85   \n",
      "     2     0.054  262.29  46.83  31.75  39.29  0.061  260.12  38.92  42.42   \n",
      "     3     0.055  263.82  48.13  27.24  37.68  0.059  260.66  36.22  42.39   \n",
      "     4     0.053  265.33  46.09  23.91  35.00  0.058  261.71  35.32  41.06   \n",
      "     5     0.050  265.66  41.46  26.65  34.06  0.053  261.20  31.66  48.09   \n",
      "\n",
      "                  ...     26                                  27          \\\n",
      "             VHI  ...    SMN     SMT    VCI    TCI    VHI    SMN     SMT   \n",
      "Year Week         ...                                                      \n",
      "1982 1     43.10  ...  0.056  262.27  52.32  38.91  45.61  0.083  261.70   \n",
      "     2     40.67  ...  0.053  262.89  51.85  35.01  43.43  0.092  264.40   \n",
      "     3     39.30  ...  0.052  263.78  51.81  32.00  41.91  0.097  265.74   \n",
      "     4     38.19  ...  0.051  264.98  49.19  31.34  40.26  0.101  267.73   \n",
      "     5     39.88  ...  0.049  265.84  43.77  34.11  38.94  0.102  268.87   \n",
      "\n",
      "                                \n",
      "             VCI    TCI    VHI  \n",
      "Year Week                       \n",
      "1982 1     57.78  41.22  49.50  \n",
      "     2     65.82  31.42  48.62  \n",
      "     3     70.62  27.11  48.86  \n",
      "     4     71.82  20.73  46.28  \n",
      "     5     65.88  21.34  43.61  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'empty']\n",
    "\n",
    "for province_id in range(1, 28):\n",
    "    pattern = rf'vhi_id_{province_id}_\\d{{4}}-\\d{{2}}-\\d{{2}}_\\d{{2}}-\\d{{2}}-\\d{{2}}\\.csv'\n",
    "    \n",
    "    matched_files = [f for f in os.listdir(data_dir) if re.fullmatch(pattern, f)]\n",
    "    \n",
    "    if not matched_files:\n",
    "        print(f\"File for province_id {province_id} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    latest_file = os.path.join(data_dir, matched_files[0])\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(latest_file, header=1, names=headers)\n",
    "        df = df.drop(columns=[\"empty\"], errors=\"ignore\")\n",
    "        df = df.set_index([\"Year\", \"Week\"])\n",
    "        df.columns = pd.MultiIndex.from_product([[str(province_id)], df.columns])\n",
    "        dfs.append(df)\n",
    "        print(f\"File {latest_file} processed successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {latest_file}: {e}\")\n",
    "\n",
    "if dfs:\n",
    "    final_df = pd.concat(dfs, axis=1)\n",
    "    final_df.to_csv(\"vhi_final.csv\")\n",
    "    print(\"File 'vhi_final.csv' saved successfully!\")\n",
    "    print(final_df.head())\n",
    "else:\n",
    "    print(\"No matching files found for merging.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:38:30.775442600Z",
     "start_time": "2025-03-11T12:38:30.388725400Z"
    }
   },
   "id": "644fa8536e3090c0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30e026190dfcd766"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week\n",
      "1     63.87\n",
      "2     65.72\n",
      "3     66.63\n",
      "4     68.21\n",
      "5     67.69\n",
      "6     64.41\n",
      "7     59.08\n",
      "8     54.77\n",
      "9     53.42\n",
      "10    54.02\n",
      "11    54.63\n",
      "12    54.79\n",
      "13    56.36\n",
      "14     54.5\n",
      "15    51.77\n",
      "16    51.83\n",
      "18    59.32\n",
      "19    63.37\n",
      "20    38.47\n",
      "21    67.84\n",
      "22     70.8\n",
      "23    73.09\n",
      "24    74.29\n",
      "25    76.87\n",
      "26    77.32\n",
      "27    74.84\n",
      "28    72.94\n",
      "29     71.8\n",
      "30     71.4\n",
      "31    71.63\n",
      "32    71.44\n",
      "33    67.82\n",
      "34     63.1\n",
      "35    58.52\n",
      "36    53.67\n",
      "37    49.36\n",
      "38    45.27\n",
      "39    42.05\n",
      "40    42.44\n",
      "41     43.7\n",
      "42    44.92\n",
      "43    46.93\n",
      "44    48.76\n",
      "45    47.85\n",
      "46    44.68\n",
      "47    43.41\n",
      "48    45.15\n",
      "49    49.03\n",
      "50    46.52\n",
      "51    46.12\n",
      "52    48.14\n",
      "Name: (8, VHI), dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path = \"vhi_final.csv\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Виводить дані по VHI в залежності від області та року\"\"\"\n",
    "    df = pd.read_csv(file_path, header=[0, 1], index_col=[0, 1])\n",
    "    df = df.replace(-1, pd.NA).dropna()\n",
    "    return df\n",
    "\n",
    "def get_vhi_series(df, region_id, year):\n",
    "    return df.loc[year, (str(region_id), \"VHI\")]\n",
    "\n",
    "df = load_data(file_path)\n",
    "\n",
    "print(get_vhi_series(df, 8, 2005))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:39:31.973686700Z",
     "start_time": "2025-03-11T12:39:31.891414100Z"
    }
   },
   "id": "a40ccab338ec8d9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 9.36, 'max': 91.42, 'mean': 52.74688356164383, 'median': 53.0475}\n"
     ]
    }
   ],
   "source": [
    "def get_extremes(df, region_ids, years):\n",
    "    \"\"\"Знаходить мінімальні, максимальні значення VHI, середнє та медіану для вказаних областей та років.\"\"\"\n",
    "    selected_data = df.loc[years, (list(map(str, region_ids)), \"VHI\")]\n",
    "    selected_data = selected_data.dropna()\n",
    "    return {\n",
    "        \"min\": float(selected_data.min().min()),\n",
    "        \"max\": float(selected_data.max().max()),\n",
    "        \"mean\": float(selected_data.mean().mean()),\n",
    "        \"median\": float(selected_data.median().median())\n",
    "    }\n",
    "\n",
    "print(get_extremes(df, [8, 10], range(2000, 2006)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:40:02.022471Z",
     "start_time": "2025-03-11T12:40:01.961634400Z"
    }
   },
   "id": "961ff27ca1be14de"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               3      5\n",
      "             VHI    VHI\n",
      "Year Week              \n",
      "1995 4     47.22  57.56\n",
      "     5     46.49  51.35\n",
      "     6     44.28  42.64\n",
      "     7     41.76  34.23\n",
      "     8     40.26  29.13\n",
      "     9      40.3  26.64\n",
      "     10    41.32  25.49\n",
      "     11    41.83  25.71\n",
      "     12    44.88  26.72\n",
      "     13    47.86  28.79\n",
      "     14     50.4  29.97\n",
      "     15    52.28  31.51\n",
      "     16    52.43  33.09\n",
      "     17    53.37  38.15\n",
      "     18    54.28  43.17\n",
      "     19    54.43  46.68\n",
      "     20     53.9  49.03\n",
      "     21    53.29  50.29\n",
      "     22    50.55  49.21\n",
      "     23    49.39  47.87\n",
      "     24    48.78  49.91\n",
      "     25    46.58  56.72\n",
      "     26    42.75  61.35\n",
      "     27    38.85  62.43\n",
      "     28    36.08  62.02\n",
      "     29    34.41  62.29\n",
      "     30    33.04  62.96\n",
      "     31    31.01  63.84\n",
      "     32    30.42  64.83\n",
      "     33    30.46  65.45\n",
      "     34     31.6  65.59\n",
      "     35    35.36  65.31\n",
      "     36    41.11  63.61\n",
      "     37    45.81  60.76\n",
      "     38    49.09  60.09\n",
      "     39    51.05   58.9\n",
      "     40    52.19  57.49\n",
      "     41    49.85  55.01\n",
      "     42    50.39  52.34\n",
      "     43    49.43  50.63\n",
      "     44    45.95  46.97\n",
      "     45    41.15  44.04\n",
      "     46    39.32  40.58\n",
      "     47    38.36  36.14\n",
      "     48    37.27  32.87\n",
      "     49    38.04  31.97\n",
      "     50     37.9  27.78\n",
      "     51    38.06  26.11\n",
      "     52    38.34  28.88\n",
      "1996 1     38.03  34.44\n",
      "     2      37.5  38.04\n",
      "     3     37.14   37.4\n",
      "     4     37.99   37.7\n",
      "     5     38.87   39.8\n",
      "     6     41.05  42.01\n",
      "     7     43.19  42.43\n",
      "     8     44.02  42.13\n",
      "     9     44.53   42.4\n",
      "     10    44.07   42.4\n",
      "     11    43.52  42.21\n",
      "     12    43.36  41.55\n",
      "     13    43.15  42.32\n",
      "     14    44.09  43.15\n",
      "     15    42.58   43.9\n",
      "     16    38.54   44.1\n",
      "     17     35.9  47.39\n",
      "     18    35.08  50.74\n",
      "     19    37.26  53.13\n",
      "     20     36.9  54.72\n",
      "     21    35.24  58.03\n",
      "     22     35.1  57.22\n",
      "     23    35.05  52.99\n",
      "     24    34.35  47.59\n",
      "     25    34.67  41.76\n",
      "     26    37.54  36.71\n",
      "     27    44.13  32.81\n",
      "     28    50.81  29.41\n",
      "     29    54.75  27.68\n",
      "     30    57.71  29.05\n",
      "     31    59.29  33.47\n",
      "     32    60.49  39.27\n",
      "     33    61.15  46.61\n",
      "     34    60.83  54.22\n",
      "     35    60.89  62.22\n",
      "     36     60.8  69.46\n",
      "     37    60.09   74.1\n",
      "     38    56.36  75.05\n",
      "     39    51.17  72.96\n",
      "     40    47.88  68.84\n",
      "     41    41.81  62.16\n",
      "     42    36.89  55.88\n",
      "     43    34.93  50.39\n",
      "     44    32.21  42.91\n",
      "     45    31.34  40.06\n",
      "     46    34.59  39.34\n",
      "     47    36.73  39.13\n",
      "     48    37.45  40.03\n",
      "     49    36.58  39.62\n",
      "     50     37.0  38.98\n",
      "     51    38.87   40.2\n",
      "     52    38.51  38.97\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_for_range(df, region_ids, start_year, end_year):\n",
    "    \"\"\"Повертає ряд VHI за вказаний діапазон років для вказаних областей.\"\"\"\n",
    "    return df.loc[start_year:end_year, (list(map(str, region_ids)), \"VHI\")].dropna()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(get_vhi_for_range(df, [3, 5], 1995, 1996))\n",
    "pd.reset_option(\"display.max_rows\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:44:57.443943700Z",
     "start_time": "2025-03-11T12:44:57.391233Z"
    }
   },
   "id": "8dad9b232bc1bb2a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'year': 2000, 'regions': ['1', '8', '11', '12', '20', '24'], 'vhi_values': [10.68, 9.36, 10.6, 6.49, 8.14, 11.25]}, {'year': 2007, 'regions': ['4', '9', '16', '17', '26'], 'vhi_values': [13.28, 12.23, 5.94, 5.52, 10.88]}]\n"
     ]
    }
   ],
   "source": [
    "def detect_drought_years(df, threshold=20):\n",
    "    \"\"\"Виявляє роки, коли екстремальна посуха торкнулася більше threshold% областей.\"\"\"\n",
    "    total_regions = len(df.columns.get_level_values(0).unique())\n",
    "    critical_regions = int((threshold / 100) * total_regions)\n",
    "    \n",
    "    drought_years = []\n",
    "    for year in df.index.get_level_values(0).unique():\n",
    "        yearly_data = df.loc[year, (slice(None), \"VHI\")]\n",
    "        drought_areas = (yearly_data < 15).sum(axis=0)\n",
    "        affected_regions = drought_areas[drought_areas > 0].index.get_level_values(0).tolist()\n",
    "        \n",
    "        if len(affected_regions) >= critical_regions:\n",
    "            drought_years.append({\n",
    "                \"year\": year,\n",
    "                \"regions\": affected_regions,\n",
    "                \"vhi_values\": yearly_data.loc[:, affected_regions].min().tolist()\n",
    "            })\n",
    "    \n",
    "    return drought_years\n",
    "\n",
    "print(detect_drought_years(df, threshold=20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:45:07.478021100Z",
     "start_time": "2025-03-11T12:45:07.345084800Z"
    }
   },
   "id": "4c8c4c06a557618b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2fafb03050caf179"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
